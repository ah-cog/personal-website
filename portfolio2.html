<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>Michael Gubbels</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- Le styles -->
    <link href="./assets/css/bootstrap.css" rel="stylesheet">
    <style>
      body {
        padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
      }
    </style>
    <link href="./assets/css/bootstrap-responsive.css" rel="stylesheet">
    
    <link href="./assets/css/style.css" rel="stylesheet">

    <!-- Le HTML5 shim, for IE6-8 support of HTML5 elements -->
    <!--[if lt IE 9]>
      <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->

    <!-- Le fav and touch icons -->
    <link rel="shortcut icon" href="./assets/ico/favicon.ico">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="./assets/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="./assets/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="./assets/ico/apple-touch-icon-57-precomposed.png">
    
    <!--
    <script type="text/javascript" src="https://www.google.com/jsapi?key=ABQIAAAAEOOWav0KSyX9SZ23kpsdPRTs-F3xFRS5jilMVFuI7jogkuUpHRRKjz7aE5SqqUoPbC1fSQ5dn9lQZQ"></script>
	<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.7.0/jquery.min.js"></script>
	-->
	
	<script type="text/javascript" src="https://www.google.com/jsapi"></script>
	<script type="text/javascript">
		google.load("jquery", "1.7.1");
	</script>
    
    <link href='http://fonts.googleapis.com/css?family=Quicksand:300,400|Muli|Terminal+Dosis|Comfortaa' rel='stylesheet' type='text/css'>
    
    <script type="text/javascript">
    $(document).ready(function() {
    	$('#menu_about').hover(
    		function() { 
    			$('#menu_cursor').css('top', 70); 
    		},
    		function() {});
    	$('#menu_cv').hover(
    		function() { 
    			$('#menu_cursor').css('top', 104); 
    		},
    		function() {});
    	$('#menu_portfolio').hover(
    		function() { 
    			$('#menu_cursor').css('top', 137); 
    		},
    		function() {});
    	$('#menu_play').hover(
    		function() { 
    			$('#menu_cursor').css('top', 172); 
    		},
    		function() {});
    });
    </script>
    
    <script type="text/javascript">
	
	  var _gaq = _gaq || [];
	  _gaq.push(['_setAccount', 'UA-26414404-1']);
	  _gaq.push(['_trackPageview']);
	
	  (function() {
		var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
		ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
		var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	  })();
	
	</script>
  </head>

  <body>

    <div class="container">
    
    	<div class="row">
    		<div class="span2">
    			&nbsp;
    		</div>
    	
    		<div class="span1">
    			<img src="./assets/img/brace_top.png" />
    		</div>
    		
    		<div class="span9">
    			&nbsp;
    		</div>
    	</div>
    	
    	<div class="row">
    		<div class="span2"  style="text-align: right; margin-top: 80px;">
				<p style="font-family: 'Quicksand', sans-serif; font-size: 29px; line-height: 1.2;">
    				<a id="menu_about" href="./index.html">ABOUT</a><br />
    				<a id="menu_cv" href="./cv.html">CV</a><br />
    				<a id="menu_portfolio" href="./portfolio.html">PROJECTS</a><br />
                    <a id="menu_play" href="./play.html">PLAY</a><br />
				</p>
			</div>
			
    		<div class="span10" style="background-image:url('./assets/img/brace_side.png'); background-repeat: repeat-y;">
    		
    			<div style="position: relative; margin-top: -10px; margin-bottom: -10px;">
					<div style="padding-left: 100px;">




<h1>M.S. PROJECTS</h1>
<hr />



<div class="row">
	<div class="span9">
		<img src="./assets/img/sciencekit-logo.png" alt="ScienceKit">
		<p>
			ScienceKit is an on-going exploration of emmersive scientific inquiry through the framework of story making and story sharing.  This research is an evolution of previous work on SINQ.
		</p>
		<p>
			<strong>Collaborators:</strong> Tammy Clegg (College of Education, College of Information Studies), June Ahn, Ph.D. (College of Information Studies, College of Education)
		</p>
		<p>
			<strong>Code:</strong> <a href="https://github.com/mokogobo/sciencekit">GitHub</a>
		</p>
	</div>
</div>
<br /><br /><br />




<div class="row">
	<div class="span9">
		<img src="./assets/img/sinq/sinq.png" style="width: 700px;">
		<br /><br />
		<img src="./assets/img/sff/sff.jpg" style="width: 700px;">

		<img src="./assets/img/sinq-logo.png" alt="SINQ">

		<p>
			SINQ is a web application being designed to support elementary children in capturing their questions as they arise and provide guidance toward answering their questions.  This guidance is designed into the interface and interactive mechanisms to scaffold a model of scientific inquiry to promote learning fundamental scientific inquiry skills such as question asking, hypothesis formation, identification of variables, and resource gathering.
		</p>
		<p>
			<strong>Collaborators:</strong> June Ahn, Ph.D. (College of Information Studies, College of Education), Jinyoung Kim (College of Information Studies)
		<p>
		<p>
			<strong>Code:</strong> <a href="https://github.com/mokogobo/sinq">GitHub</a>
			<br />
			<strong>Papers:</strong> CSCL 2013, iConference 2013, <a href="./portfolio/umd/sinq/SINQ-CHI-2012-WIP-Paper-Rev4.pdf">CHI 2012 WIP</a>, <a href="./portfolio/umd/sinq/SINQ-CMSC838C-Project-Paper.pdf">CMSC 838C</a>
			<br />
			<strong>Posters:</strong> <a href="./portfolio/umd/sinq/SINQ-CHI-2012-WIP-Poster-Rev2.pdf">CHI 2012</a>, <a href="./portfolio/umd/sinq/SINQ-CMSC838C-Project-Presentation.pdf">CMSC 838C</a>
		</p>
	</div>
</div>
<div class="row" style="margin-bottom: 10px;">
	<div class="span3">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/umd/sinq/screenshots/signin.png" alt="">
		</div>
	</div>
	<div class="span2">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/umd/sinq/screenshots/home.png" alt="">
		</div>
	</div>
	<div class="span2">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/umd/sinq/screenshots/question.png" alt="">
		</div>
	</div>
</div>
<br /><br /><br />



<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Social Fabric Fitness</h3>
		<p>
			Social Fabric Fitness is an exploratory research project focused on understanding how displaying personal informatics on wearable displays can affect social dynamics in groups of runners.
		</p>
		<p>
			<strong>Collaborators:</strong> Jon Froehlich, Ph.D. (Department of Computer Science), Matthew Mauriello (Department of Computer Science)
		</p>
	</div>
</div>
<br /><br /><br />



<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Cloud Computer Lab</h3>
		<p>
			This project is focused on developing a virtual research environment platform for creating, maintaining, and deploying, for example, virtual computer labs of virtual machines.
		</p>
		<p>
			<strong>Collaborators:</strong> Erik Mitchell, Ph.D. (College of Information Studies)
		</p>
	</div>
</div>
<br /><br /><br />




<h1>PREVIOUS PROJECTS</h1>
<hr />




<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Adaptive, Interactive, and Educational Kiosk Games for a Children's Zoo</h3>
		<p>
			The goal of this project was to design a system that engages children (aged three to five years) in an entertaining experience that would simultaneously teach and challenge them by adapting to their ability. I designed and implemented a graphical user interface and three games for kiosks located in an arthropod exhibit at the Lincoln Children's Zoo. I modeled games as reactive software agents that modeled player ability in real-time based on performance and adapted to that ability by making adjustments to the graphical presentation of games that influenced their level of difficulty. 
		</p>
		<p>
			<strong>Collaborators:</strong> Leen-Kiat Soh, Ph.D. (Department of Computer Science and Engineering), David Brooks, Ph.D. (Department of Teaching, Learning, and Teacher Education)
		</p>
		<p>
			<strong>Posters:</strong> <a href="./portfolio/unl/research/lcz/LCZ_UCARE_2009.pdf">UNL Undergraduate Research Conference</a>
		</p>
	</div>
</div>
<div class="row" style="margin-bottom: 10px;">
	<div class="span3">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/unl/research/lcz/screenshots/choosing_instance_play_color.png" alt="">
		</div>
	</div>
	<div class="span2">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/unl/research/lcz/screenshots/counting_ladybugs.png" alt="">
		</div>
	</div>
	<div class="span2">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/unl/research/lcz/screenshots/counting_wings.png" alt="">
		</div>
	</div>
</div>
<br /><br /><br />




<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Center for Avian Cognition</h3>
		<p>
			In this project, I collaborated with a post-doctoral researcher at the Center for Avian Cognition who was investigating the cognitive abilities of birds. I implemented programs that presented a number of stimuli to a bird on a computer display equipped with a translucent touch-sensitive surface. Birds were able to interact with the stimuli presented to them by pecking the surface on the area over a displayed stimulus. Each set of stimuli was carefully designed and presented in a manner that tested for the single cognitive ability that was required of the birds to succeed on the test. Some challenging aspects of this work were designing tests for a single cognitive ability and designing corresponding graphical environments that were comprehensible by birds.
		</p>
		<p>
			<strong>Collaborators:</strong> Cynthia Wei, Ph.D. (Center for Avian Cognition, School of Biological Sciences)
		</p>
	</div>
</div>
<br /><br /><br />




<h3 style="line-height: normal;">Multiagent System Simulation of Banking System</h3>
<p>
	In this project, we designed and implemented a multiagent system simulation of the United States banking system, in which bank agents and borrower agents interact under the operational constraints imposed by a single Federal Reserve agent. Using this (simplified) simulation, we investigated the effect of agent behaviors over a period of time under various conditions (e.g., probability that a borrower agent will default on a payment) by adjusting simulation parameterizaters (e.g., bounds on the probability that borrower agents will default on a payment). We addressed the general issue of system longevity by performing an in-depth investigation of the relationship between simulation results and initial conditions (i.e., the parameterizations and some random factors such as agent location in the simulated space).
</p>
<p>
	<strong>Collaborators:</strong> Michael Gubbels, Casey Nugent
</p>
<p>
	<strong>Code:</strong> <a href="./portfolio/unl/classes/csce475/project/Code.zip">Repast Simulation (Java)</a>
	<br />
	<strong>Report:</strong> <a href="./portfolio/unl/classes/csce475/project/Report.docx">Final</a>
</p>
<div class="row" style="margin-bottom: 10px;">
	<div class="span3">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/unl/classes/csce475/project/screenshots/WorldVisualization102.0.png" alt="">
		</div>
	</div>
	<div class="span2">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/unl/classes/csce475/project/screenshots/WorldVisualization391.0.png" alt="">
		</div>
	</div>
</div>
<br /><br /><br />



<h3 style="line-height: normal;">A Client-Server Architecture for Connecting Geographically Separated Wireless Sensor Networks</h3>
<p>
	In this project, we present a system to enable geographically separated wireless sensor networks (WSNs) to communicate via Internet connection. This system requires WSNs to register as clients to a centralized server that manages client identification and enables clients to communicate with one another by (1) relaying a message directly to another connected client, (2) broadcasting a message to all connected clients, or (3) sending a message to the server to store in its database (which other clients can access). We designed and implemented an Application Layer protocol to support communication between the server and clients using the Transmission Control Protocol (TCP). The server maintains a MySQL database of registered clients and WSN data. To demonstrate our system, we implemented three basic WSNs to demonstrate each of the three communication functionalities. One of these WSNs was connected to the array of large light panels located on the front of the Schorr Center building at the University of Nebraska–Lincoln, and initiated light shows based on the most-recent WSN sensor data stored in the server database.
</p>
<p>
	<strong>Collaborators:</strong> <a href="http://jtooker.com/">John Tooker</a>, Scott Robinson, Stephen Mkandawire
	<br />
	<strong>Class:</strong> Embedded Systems for Wireless Sensor Networks (taught by <a href="http://www.cse.unl.edu/~mcvuran/">Mehmet Can Vuran, Ph.D.</a>)
</p>
<p>
	<strong>Code:</strong> Contact me for the code.
	<br />
	<strong>Report:</strong> <a href="./portfolio/unl/classes/csce496/project/wsn_report.pdf">Final</a>
	<br />
	<strong>Slides:</strong> <a href="./portfolio/unl/classes/csce496/project/wsn_presentation.pdf">Presentation</a>
</p>
<br /><br /><br />



<h3 style="line-height: normal;">An Interactive Software Agent Prototype for User Interfaces</h3>
<p>
	(2010) The purpose of this project was to develop a software agent that provides a user interface to a system's functionality that enables users to access that functionality with little or no knowledge of the corresponding system's operating procedures. In this project, we have implemented a software agent that can proactively recognize a user and adapt its behavior to facilitate access to information about the weather conditions that corresponds to the location of the recognized user's model. This agent implementation includes (1) an online face recognition system (Eigenfaces) that detects and recognizes the faces of users in real-time using a webcam, (2) mechanisms that perform basic user modeling and (3) real-time action adaptation to recognized, modeled users, (4) a rudimentary text-based I/O system to support simple interaction, and (4) functions to retrieve and parse weather data from the Yahoo! Weather RSS feed. Users can request weather information by asking querying the agent using the text-based I/O system. This replaces the need for users to manually navigate to the information using a web browser.
</p>
<p>
	<strong>Collaborators:</strong> Michael Gubbels, Derrick Lam
	<br />
	<strong>Class:</strong> Robotics: Algorithms and Applications (taught by <a href="http://cse.unl.edu/~carrick/">Carrick Detweiler, Ph.D.</a>)
</p>
<br /><br /><br />




<h1>ART PROJECTS</h1>
<hr />




<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Feedback Installation</h3>
		<p>
			(2011) Interactive video installation and space created for my final project for Digital Literacy: Motion (ARTP 171).  The installation was created using custom software running on ten networked laptop computers that captured data, transmitted it to a central computer connected to one of two projectors.  The two projects projected in roughly opposite directions in a dark room, over the laptops, to create a virtual interactive space.  The laptops also generated audio based on characteristics of transmitted video frames and network performance.
		</p>
	</div>
</div>
<div class="row" style="margin-bottom: 10px;">
	<div class="span3">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/unl/classes/artp171/feedback/screenshots/sample005.png" alt="">
		</div>
	</div>
	<div class="span2">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/unl/classes/artp171/feedback/screenshots/sample003.png" alt="">
		</div>
	</div>
	<div class="span2">
		<div href="#" class="thumbnail">
		  <img src="./portfolio/unl/classes/artp171/feedback/screenshots/sample004.png" alt="">
		</div>
	</div>
</div>
<br /><br /><br />




<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Fields</h3>
		<p>
			(2011) Audio composition of digitally recorded sounds for Digital Literacy: Motion (ARTP 171) class at University of Nebraska–Lincoln.  This composition was created using GarageBand.</p>
		<p>
			<strong>Audio:</strong> 
			<a href="http://soundcloud.com/michaelgubbels/fields">SoundCloud</a>
		</p>
	</div>
</div>
<br /><br /><br />




<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Interpretations B Motion 1</h3>
		<p>
			(2011) Audiovisual composition created for Digital Literacy: Motion (ARTP 171) class.  The video was created by recording the projection of a handcrafted 35mm film of repeating abstract digital forms, produced by adhering prints of digital images, printed on transparent sheets, to 35mm film. These digital images were created by digitally interlacing frames extracted from original video footage of natural formations and built architecture.  This composition was assembled using Final Cut Pro.</p>
		<p>
			<strong>Video:</strong> <a href="http://vimeo.com/21623460">Vimeo</a>
		</p>
	</div>
</div>
<br /><br /><br />




<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Formations 1 + Sweep 1</h3>
		<p>
			(2011) Audiovisual composition created for Digital Literacy: Motion (ARTP 171).  The video is digitally manipulated to expose patterns in footage of white objects in a plastic bag exposed to bright light.  The audio was improvised and recorded on a software-based MIDI instrument that I programmed using pureData and controlled with my MIDI keyboard.</p>
		<p>
			<strong>Video:</strong> <a href="http://vimeo.com/20206461">Vimeo</a>
		</p>
	</div>
</div>
<br /><br /><br />




<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Life/Breath</h3>
		<p>
			(2011) Video for Visual Haiku project for Digital Literacy: Motion (ARTP 171).  The video is a recording of a performance using a green laser pointer, an HDTV, and camera configured to produce video feedback.  The video was assembled using Final Cut Pro.
		<p>
			<strong>Video:</strong> <a href="http://vimeo.com/35790466">Vimeo</a>
		</p>
	</div>
</div>
<br /><br /><br />




<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Pickpocket Remix</h3>
		<p>
			(2011) Video for Pickpocket Remix project for Digital Literacy: Motion (ARTP 171).  The video was manually cut and edited, frame-by-frame, using footage from the film Pickpocket directed by Robert Bresson.  The video was edited using Final Cut Pro.
		</p>
		<p>
			<strong>Video:</strong> <a href="https://vimeo.com/39153502">Narrative Remix</a>, <a href="https://vimeo.com/39153378">Abstract Remix</a>
		</p>
	</div>
</div>
<br /><br /><br />




<h1>UNDERGRADUATE PROJECTS</h1>
<hr />

<div class="row">
	<div class="span9">
		<h3 style="line-height: normal;">Budgeted Machine Learning of Bayesian Networks</h3>
		<p>
			Budgeted machine learning is a type of machine learning in which programs are given a budget and a collection of examples for which only the labels are known, and from which they must select and purchase particular features from particular examples from which they will learn. In my work so far, I have extended a number of existing algorithms that learn naïve Bayes classiers to learn Bayesian networks. I have observed that under some conditions, the learned Bayesian networks significantly outperform the naïve Bayes classiers. Currently, I am designing new algorithms that make use of the structural information encoded in Bayesian networks, which corresponds to mutual dependence relationships in the features of examples, in effort to improve learning performance.
		</p>
		<p>
			<strong>Collaborators:</strong> Stephen Scott, Sc.D. (Department of Computer Science and Engineering), Yaling Zheng, Ph.D. (Department of Computer Science and Engineering), Kun Deng, Ph.D. (Department of Computer Science and Engineering)
		</p>
		<p>
			<strong>Poster:</strong> 
			<a href="./portfolio/unl/research/blbn/poster.pdf">UNL Undergraduate Research Conference</a>
		</p>
	</div>
</div>
<br /><br /><br />




<h3 style="line-height: normal;">Hidden Markov Model Data Structures and Algorithms</h3>

<p>
	This project was a study of a the hidden Markov model and three associated algorithms. I implemented (1) data structures for a hidden Markov model as well as the Viterbi and Forward algorithms, and (2) the Baum-Welch algorithm. The performance of each algorithm was evaluated using data sets of amino acid sequences and binary strings.
</p>
<p>
	<strong>Code:</strong> (1) <a href="./portfolio/unl/classes/csce970/hw01/hmm_code.tar.gz">Code (C)</a>, (2) <a href="./portfolio/unl/classes/csce970/hw02/hmm_bw_code.tar">Code (Java)</a>
	<br />
	<strong>Reports:</strong> (1) <a href="./portfolio/unl/classes/csce970/hw01/hmm_report.pdf">HMM Report</a>, (2) <a href="./portfolio/unl/classes/csce970/hw02/hmm_bw_report.pdf">HMM Baum-Welch Report</a>
	<br />
	<strong>Class:</strong> Pattern Recognition (taught by Stephen Scott, Sc.D.)
</p>
<br /><br /><br />




<h3 style="line-height: normal;">Machine Learning Data Structures and Algorithms</h3>
<p>
	This project was a study of a three machine learning techniques. I implemented and evaluated the performance of (1) the ID3 decision tree learning algorithm, (2) an artificial neural network with back propagation, and (3) the naïve Bayes classifier for several data sets from the UCI Machine Learning Repository. This project was completed for a Machine Learning class in the fall of 2008.
</p>
<p>
	<strong>Code:</strong> (1) <a href="./portfolio/unl/classes/csce478/hw1/id3_code.tar.gz">Code (Ruby)</a>, (2) <a href="./portfolio/unl/classes/csce478/hw2/ann_code.tar">Code (C++)</a>, (3) <a href="./portfolio/unl/classes/csce478/hw3/nb_code.tar">Code (Ruby)</a>
	<br />
	<strong>Reports:</strong> (1) <a href="./portfolio/unl/classes/csce478/hw1/id3_report.pdf">ID3 Report</a>, (2) <a href="./portfolio/unl/classes/csce478/hw2/ann_report.pdf">ANN Report</a>, (3) <a href="./portfolio/unl/classes/csce478/hw3/nb_report.pdf">NBC Report</a>
	<br />
	<strong>Class:</strong> Machine Learning (taught by Stephen Scott, Sc.D.)
</p>
<br /><br /><br />




<h3 style="line-height: normal;">16-Bit Asynchronous Divider</h3>
<p>
	In this project, I designed, implemented, and simulated a 16-bit asynchronous divider using the VHDL hardware description language and the Quartus II FPGA design software. This project was completed for a Digital Logic Design class in the fall of 2008.
</p>
<p>
	<strong>Code:</strong> <a href="./portfolio/unl/classes/elec370/project/async_16bit_divider_code.tar.gz">Code (VHDL)</a>
	<br />
	<strong>Class:</strong> Digital Logic Design (taught by David J. Russell)
</p>
<br /><br /><br />




<h3 style="line-height: normal;">User-Level Multithreading for Altera DE2</h3>
<p>
	In this project, I implemented thread management mechanisms and designed mutual exclusion and thread synchronization mechanisms to support threading on the uniprocessor on the Altera DE2 development board. The project was completed for an Operating System Kernels class in the fall of 2008.
</p>
<p>
	<strong>Class:</strong> Operating System Kernels (taught by <a href="http://www.cse.unl.edu/~ylu/">Ying Lu, Ph.D.</a>)
</p>
<br /><br /><br />




<h3 style="line-height: normal;">24-bit Multicycle Reduced Instruction Set Architecture Processor</h3>
<p>
	In this project, I designed a 24-bit instruction set architecture (ISA) based on the 32-bit MIPS ISA, and designed and implemented a 24-bit RISC multicycle processor to support that 24-bit ISA, and implemented an assembler for the ISA. The processor was designed using the Quartus II design software and simulated on an Altera FPGA development board. The project was completed for a Computer Organization class in the fall of 2007.
</p>
<p>
	<strong>Class:</strong> Computer Organization (taught by <a href="http://cse.unl.edu/~riedesel/">Charles Riedesel, Ph.D.</a>)
</p>




					</div>
					
					<!-- 63, 80 99 -->
					<div id="menu_cursor" style="position: absolute; top: 137px; left: 0px;">
						<img src="./assets/img/brace_center.png" />
					</div>
				</div>
				
			</div>
    	</div>
    
    	<div class="row" style="margin-bottom: 65px;">
			<div class="span2">
				&nbsp;
			</div>
			
			<div class="span1">
				<img src="./assets/img/brace_bottom.png" />
			</div>
			
			<div class="span9">
				&nbsp;
			</div>
    	</div>
      

    </div> <!-- /container -->

    <!-- Le javascript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <!--
    <script src="./js/jquery.js"></script>
    <script src="./js/bootstrap-transition.js"></script>
    <script src="./js/bootstrap-alert.js"></script>
    <script src="./js/bootstrap-modal.js"></script>
    <script src="./js/bootstrap-dropdown.js"></script>
    <script src="./js/bootstrap-scrollspy.js"></script>
    <script src="./js/bootstrap-tab.js"></script>
    <script src="./js/bootstrap-tooltip.js"></script>
    <script src="./js/bootstrap-popover.js"></script>
    <script src="./js/bootstrap-button.js"></script>
    <script src="./js/bootstrap-collapse.js"></script>
    <script src="./js/bootstrap-carousel.js"></script>
    <script src="./js/bootstrap-typeahead.js"></script>
    -->

  </body>
</html>
